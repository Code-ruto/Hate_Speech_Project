{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593c5b65",
   "metadata": {},
   "source": [
    "# Youtube Hate Speech ML Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f895df",
   "metadata": {},
   "source": [
    "### First thing is to import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad297f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50187f1a",
   "metadata": {},
   "source": [
    "### Various libraries will be imported for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.util import pr\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034d0d8",
   "metadata": {},
   "source": [
    "### `nltk.corpus` is a module by Natural language toolkit. Contains large sets of text for linguistic analysis and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae03f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de55c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_data.csv\")\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# Drop any `NaN` values\n",
    "# Summon the info of dataset.\n",
    "\n",
    "print(df.columns.tolist()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01e6d3",
   "metadata": {},
   "source": [
    "### We used the `.map` function to assign 0, 1, and 2 to \"Hate Speech Detected\", \"Offensive language detected\", and \"No hate and offensive speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117eadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['class'].map({0:\"Hate Speech Detected\", 1:\"Offensive language detected\", 2:\"No hate and offensive speech\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'].info\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f32f7",
   "metadata": {},
   "source": [
    "### We create a `tweets` and `labels` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tweet', 'labels']]\n",
    "df = df[['tweet', 'labels']].fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6c9de",
   "metadata": {},
   "source": [
    "### Now begins the process of cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ec08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text) \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', \"\", text)\n",
    "    text = [word for word in text.split() if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean)\n",
    "df[\"tweet\"] = df[\"tweet\"].dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb3635",
   "metadata": {},
   "source": [
    "### Our data is ready. Now to build the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[\"tweet\"])\n",
    "y = np.array(df[\"labels\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.33, random_state = 42)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0354e40",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"i will kill you\"\n",
    "df = cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fafbe8",
   "metadata": {},
   "source": [
    "## Conclusion of  Hate Speech Detection project\n",
    "### This project ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Citation: Simplilearn. (2022, November 16). Hate speech detection using machine learning: \n",
    "ML projects using python: Simplilearn. YouTube. https://youtu.be/jbexvUovHxw?si=jJGUJVUIWDSDtujG \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
